---
title: "Stop Anthropomorphizing AI"
date: '2026-01-08T23:56:29.37Z'
permalink: /posts/2026/stop-anthropomorphizing-ai/index.html
description: "Grok is being used for horrible purposes and the media all too often wants to try to make AI and LLMs 'human'."
tags:
  - AI
  - Grok
  - Elon Musk
---
Recently Grok, Elon Musk's AI agent extraordinaire has been in the news for [allowing people to produce child sexual abuse material (CSAM)](https://www.404media.co/groks-ai-csam-shitshow/). This should be a huge story, but instead, the mainstream media is making a mockery of itself bending over backwards to either ignore it or completely miscategorizing what is happening.
<!-- excerpt -->

I've seen [plenty](https://www.404media.co/groks-ai-csam-shitshow/) [of](https://www.pcmag.com/news/xs-grok-chatbot-apologizes-for-creating-sexualized-images-of-underage-girls) [articles](https://thehill.com/policy/technology/5669917-elon-musk-ai-chatbot-grok-apologizes/) with headlines saying how Grok apologized for sexualizing young girls, and all I want to do is scream at my screen: "AI CAN'T APOLOGIZE! IT'S NOT FUCKING HUMAN!"

*Okay...just breathe...*

That some of our biggest news sources can't recognize this disconnect, well it explains a lot about where we are as a nation and as a society.

We need to stop treating AI, LLMs, chatbots as if they're human. They're not. They're computer algorithms. They might be "smarter" than anything we've had in the past, but they're still just computer code. They can't apologize, they don't have the human capacity to admit wrongdoing. If they "apologized", it's only because they were prompted to.

And none of this even begins to address what Elon Musk and xAI allowed Grok to *actually do*. The fact that there were no safeguards baked into xAI to tell it to not generate child porn just blows my mind. It's something so completely obvious that a sane person would realize that some asshole would no doubt try to do that with their tool. I wish this weren't the case, but human nature is a bitch. I don't know how hard it is to implement it from a coding perspective, but I feel like most of the bigger players like OpenAI have guardrails in place to try to stop the worst of it.

I don't particularly like the fact that Google and Apple (Apple especially) are gatekeepers of what software can be installed on our phones, but if they're going to be the arbiters, why the hell are they allowing a CSAM generation tool to remain on their app stores?